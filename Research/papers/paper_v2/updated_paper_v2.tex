\documentclass[journal]{IEEEtran}

% Packages
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{cite}
\usepackage{url}
\usepackage{hyperref}
\usepackage{float}
\usepackage{booktabs}
\usepackage{multirow}

% Correct hyphenation
\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}

\title{Wavelength-Division Ternary Computing II:\\N-Radix Optical AI Accelerator vs. B200 and Frontier}

\author{Christopher Riner%
\thanks{Independent Researcher: Chesapeake, VA, US. Email: chrisriner45@gmail.com}}

\maketitle

\begin{abstract}
We present N-Radix, an open-source optical accelerator architecture based on wavelength-division ternary logic, freely available for anyone to build upon. Building on our prior theoretical work \cite{riner2026wavelength} and open-source simulation framework \cite{riner2026software}\footnote{Source code and designs available at: \url{https://github.com/jackwayne234/-wavelength-ternary-optical-computer}}, we now describe a complete systolic array architecture optimized for AI/ML workloads. The design employs a novel log-domain tower scaling mechanism where the N-Radix Input/Output Converter (NR-IOC) reinterprets base-3 trits as $\text{trit}^3$ (3\textsuperscript{3} encoding), yielding up to 9$\times$ throughput improvement for addition operations. The architecture further leverages wavelength-division multiplexing (WDM) with up to 6 collision-free wavelength triplets in standard telecom bands, effectively multiplying compute throughput 6$\times$—the core mechanism by which wavelength encoding bypasses the radix economy penalty. We analyze the practical limits of this scaling approach, showing that while 3\textsuperscript{3} encoding is achievable with standard 64-bit hardware, higher towers (3\textsuperscript{3}\textsuperscript{3}\textsuperscript{3}) would require 12 terabit registers—placing them beyond physical realizability. For real-world matrix multiplication workloads (50\% multiply, 50\% add), the architecture delivers approximately 1.8$\times$ throughput improvement via Amdahl's Law. At 960$\times$960 scale, this yields 148 PFLOPS per chip for matrix multiply—59$\times$ NVIDIA's B200 (2.5 PFLOPS) while consuming an estimated 400W versus 1,000W. Compared to Frontier—the most powerful supercomputer in the world at 1,200 PFLOPS and 21 MW—equivalent performance would require only 8 N-Radix chips consuming less than 0.02\% of the power.
\end{abstract}

\begin{IEEEkeywords}
Ternary computing, optical computing, N-Radix, systolic array, wavelength division, radix economy, log-domain computing, AI accelerator, hardware security
\end{IEEEkeywords}

\section{Introduction}

In our prior work \cite{riner2026wavelength}, we demonstrated that wavelength-division ternary logic fundamentally bypasses the radix economy penalty that has historically prevented ternary computing from practical realization. While transistor-based ternary requires approximately 40$\times$ more hardware per trit compared to binary bits, wavelength differentiation cost is independent of the number of states.

This paper extends that theoretical foundation into a complete accelerator architecture we call \textbf{N-Radix}---named for its ability to operate at any radix without penalty. The design is optimized for AI and machine learning workloads. We introduce:

\begin{enumerate}
\item A \textbf{systolic array architecture} where processing elements (PEs) perform optical add/subtract operations on wavelength-encoded trits
\item \textbf{Log-domain tower scaling} that increases effective throughput by reinterpreting trit values at the system boundary
\item \textbf{N-Radix Input/Output Converter (NR-IOC)} specifications for bridging binary electronic systems with optical ternary computation
\item \textbf{Practical performance analysis} showing realistic throughput gains for matrix multiply workloads
\item \textbf{FDTD simulation validation} of clock distribution and WDM channel isolation across multiple array sizes
\item \textbf{Architectural security}: The optical compute core has no software attack surface—the geometry is the program. System interfaces still require traditional security
\end{enumerate}

\section{Wavelength Encoding Review}

\subsection{Balanced Ternary States}

Each ternary digit (trit) is encoded as one of three discrete wavelengths:

\begin{table}[H]
\centering
\caption{Wavelength-Trit Mapping (Collision-Free)}
\begin{tabular}{@{}ccc@{}}
\toprule
\textbf{Trit Value} & \textbf{Wavelength} & \textbf{Band} \\
\midrule
$-1$ & 1550 nm & C-Band Telecom \\
$0$ & 1310 nm & O-Band Telecom \\
$+1$ & 1064 nm & Nd:YAG Standard \\
\bottomrule
\end{tabular}
\label{tab:wavelengths}
\end{table}

This triplet was selected to ensure all six Sum-Frequency Generation (SFG) mixer outputs are spectrally unique with $>$10 nm spacing, avoiding the output collision present in earlier wavelength selections.

\subsection{Why Wavelength Encoding Bypasses Radix Economy}

In transistor-based systems, distinguishing $r$ voltage states requires circuitry proportional to $r$, resulting in a hardware penalty that negates ternary's theoretical 58\% information density advantage. In wavelength-encoded systems, a wavelength-selective switch (ring resonator) has approximately constant complexity regardless of how many wavelengths it distinguishes. The cost model becomes:

\begin{equation}
\text{Cost}_{\text{wavelength}} \approx C_{\text{switch}} + C_{\text{demux}}/\text{fanout}
\end{equation}

where $C_{\text{switch}}$ is approximately \textbf{constant} regardless of radix.

\section{N-Radix Architecture}

\subsection{Systolic Array Design}

N-Radix employs a systolic array architecture—a well-established design pattern dating to Kung and Leiserson's foundational work \cite{kung1982}, now widely used in modern AI accelerators \cite{jouppi2017}. Data flows through a 2D grid of Processing Elements (PEs), with each PE performing multiply-accumulate operations as data passes through. The key difference: N-Radix PEs operate on wavelength-encoded ternary values rather than electronic binary.

\begin{figure}[H]
\centering
\begin{verbatim}
    Weight inputs (stationary in PEs)
                ↓
    ┌─────────────────────────────────┐
    │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
A → │   PE─PE─PE─PE─PE─PE─PE─PE─PE → C
c   │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
t   │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
i   │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
v   │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
a   │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
t   │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
i   │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
o   │             ↓                   │
n   │      Accumulated outputs        │
s   └─────────────────────────────────┘
\end{verbatim}
\caption{Systolic array topology. Activations stream from left, weights are stationary in PEs, accumulated outputs flow down.}
\label{fig:systolic}
\end{figure}

\subsection{Processing Element Design}

A key architectural simplification: PEs do \textbf{not} store weights locally. Instead, weights are stored in the CPU's 3-tier optical RAM hierarchy and \textbf{streamed} to PEs via waveguide routing. This eliminates the need for exotic per-PE tristable storage, dramatically improving fabrication yield.

Each PE contains only:

\begin{enumerate}
\item \textbf{SFG mixer}: Performs optical multiply (in log domain) or add (in linear domain)
\item \textbf{Waveguide routing}: Receives streaming weights from optical RAM tiers
\item \textbf{Accumulator}: Aggregates partial sums
\end{enumerate}

\subsubsection{Weight Streaming Architecture}

Rather than storing weights in bistable Kerr resonators at each PE---which would require reliable tristable optical memory at every processing element---the architecture leverages the CPU's existing optical RAM infrastructure:

\begin{itemize}
\item \textbf{L1 optical cache}: Fastest access, smallest capacity (per-core)
\item \textbf{L2 optical cache}: Shared across core clusters
\item \textbf{Main optical RAM}: Bulk weight storage using Kerr-effect memory
\end{itemize}

Weights stream from the appropriate RAM tier to PEs via dedicated waveguide channels. This ``weight streaming'' approach mirrors how modern GPUs fetch weights from HBM rather than storing them in register files.

\subsubsection{Fabrication Advantages}

This architectural choice yields significant practical benefits:

\begin{itemize}
\item \textbf{Simpler PEs}: Each PE is just an SFG mixer plus waveguide routing---no exotic tristable storage required
\item \textbf{Higher yield}: Fewer complex components per PE means fewer failure points
\item \textbf{Unified memory}: The CPU's optical RAM serves double duty as accelerator weight storage
\item \textbf{Flexibility}: Weight patterns can change dynamically without PE reprogramming
\end{itemize}

The trade-off is increased waveguide routing complexity, but modern silicon photonics can handle the required channel density.

\subsection{PE Types and Operations}

The architecture employs two types of PEs:

\begin{table}[H]
\centering
\caption{Processing Element Types}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{PE Type} & \textbf{Domain} & \textbf{Physical Operation} \\
\midrule
ADD/SUB & Linear & Optical add/subtract \\
MUL/DIV & Log & Optical add/subtract (= mul/div) \\
\bottomrule
\end{tabular}
\end{table}

Both PE types perform identical physical operations (optical add/subtract). The difference is purely in interpretation: MUL/DIV PEs operate on log-encoded values, so optical addition corresponds to multiplication in the original linear domain.

\section{Log-Domain Tower Scaling}

\subsection{The Core Insight}

In the log domain:
\begin{align}
\log(A \times B) &= \log(A) + \log(B) \\
\log(A / B) &= \log(A) - \log(B)
\end{align}

Multiplication and division become addition and subtraction—enabling all arithmetic using only add/subtract hardware.

Taking this further, in the \textbf{log-log domain}:
\begin{equation}
\log(\log(X^n)) = \log(n \cdot \log(X)) = \log(n) + \log(\log(X))
\end{equation}

Exponentiation becomes addition. Each additional log level converts a harder operation into simple add/subtract.

\subsection{3\textsuperscript{3} Encoding}

Rather than adding hardware complexity, we increase effective throughput by having the NR-IOC \textbf{reinterpret} what each trit represents:

\begin{table}[H]
\centering
\caption{Tower Scaling Levels}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Level} & \textbf{Domain} & \textbf{Trit Represents} & \textbf{Hardware} \\
\midrule
0 & Linear & trit & Add/sub \\
1 & Log & trit & Add/sub = mul/div \\
2 & Log-log & trit$^3$ & Add/sub \\
\bottomrule
\end{tabular}
\end{table}

The optical hardware remains identical—3 physical states, 3 wavelengths. The NR-IOC handles encoding/decoding at the boundary.

\subsection{Practical Implementation}

Both ADD/SUB and MUL/DIV PEs use \textbf{3\textsuperscript{3} encoding}:

\begin{itemize}
\item ADD/SUB PEs: trit$^3$ represents addition values
\item MUL/DIV PEs: trit$^3$ represents multiplication values (in log domain)
\end{itemize}

The NR-IOC knows which PE type it addresses and applies the correct interpretation.

\textbf{Important:} This is why the \textbf{9× throughput boost from 3\textsuperscript{3} encoding only applies to ADD/SUB operations}. We upgraded the ADD/SUB PEs to operate in log-log domain because addition remains addition, providing 9× more compute with the same hardware. MUL/DIV PEs cannot receive the same upgrade because traditional hardware cannot handle the requirements—see the following subsection for why this is mathematically beyond any physical computer.

\subsection{Why 3\textsuperscript{3}\textsuperscript{3}\textsuperscript{3} Is Beyond Engineering}

Theoretically, MUL/DIV operations could achieve pure add/subtract at tower level 4 (3\textsuperscript{3}\textsuperscript{3}\textsuperscript{3}). However, this would require:

\begin{equation}
3^{3^{3^3}} = 3^{3^{27}} = 3^{7,625,597,484,987}
\end{equation}

This number has approximately \textbf{3.6 trillion decimal digits} and would require:

\begin{itemize}
\item \textbf{12 terabit registers} (12 trillion bits)
\item \textbf{1.5 terabytes} to store a single number
\end{itemize}

\begin{table}[H]
\centering
\caption{Bit Width Comparison}
\begin{tabular}{@{}lrl@{}}
\toprule
\textbf{System} & \textbf{Bits} & \textbf{Max Value} \\
\midrule
Standard & 64 & $\sim 10^{19}$ \\
Extended & 128 & $\sim 10^{38}$ \\
Cryptographic & 256 & $\sim 10^{77}$ \\
Large & 512 & $\sim 10^{154}$ \\
\textbf{3\textsuperscript{3}\textsuperscript{3}\textsuperscript{3}} & \textbf{12 trillion} & $\sim 10^{3.6 \text{ trillion}}$ \\
\bottomrule
\end{tabular}
\end{table}

This is not future hardware—it is mathematically beyond any physical computer. Therefore, \textbf{3\textsuperscript{3} encoding is the practical ceiling}.

\section{Performance Analysis}

\subsection{Throughput with 3\textsuperscript{3} Encoding}

The 3\textsuperscript{3} encoding provides a 9$\times$ effective throughput increase for operations that benefit from it. However, \textbf{only ADD/SUB operations benefit}—MUL/DIV operations remain at baseline throughput. This distinction is critical for understanding real-world performance.

\subsection{Real-World Matrix Multiply Performance}

Matrix multiplication consists of approximately:
\begin{itemize}
\item 50\% multiply operations
\item 50\% add operations (accumulation)
\end{itemize}

Applying Amdahl's Law:

\begin{equation}
\text{Speedup} = \frac{1}{\frac{0.5}{9} + \frac{0.5}{1}} = \frac{1}{0.056 + 0.5} \approx 1.8\times
\end{equation}

\begin{table}[H]
\centering
\caption{Performance by Workload Type}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Workload} & \textbf{ADD \%} & \textbf{MUL \%} & \textbf{Boost} \\
\midrule
Matrix multiply & 50\% & 50\% & $\sim$1.8$\times$ \\
Transformer attention & 60\% & 40\% & $\sim$2.1$\times$ \\
Pure accumulation & 100\% & 0\% & 9$\times$ \\
Pure multiply & 0\% & 100\% & 1$\times$ \\
\bottomrule
\end{tabular}
\label{tab:performance}
\end{table}

\textbf{Key insight:} The 9$\times$ boost only applies to ADD-heavy workloads (e.g., pure accumulation, vector addition). For realistic AI workloads like matrix multiplication, the 50/50 split between ADD and MUL operations limits the effective boost to $\sim$1.8$\times$ via Amdahl's Law. This is still substantial—but claims must be workload-specific.

\subsection{Scaling Projections}

\begin{table}[H]
\centering
\caption{Array Size vs Performance (Three Modes)}
\begin{tabular}{@{}lrrrr@{}}
\toprule
\textbf{Array} & \textbf{PEs} & \textbf{Base Mode} & \textbf{3\textsuperscript{3} MatMul} & \textbf{3\textsuperscript{3} Pure ADD} \\
\midrule
27$\times$27 & 729 & 65 TFLOPS & 117 TFLOPS & 583 TFLOPS \\
81$\times$81 & 6,561 & 583 TFLOPS & 1.0 PFLOPS & 5.2 PFLOPS \\
243$\times$243 & 59,049 & 5.2 PFLOPS & 9.4 PFLOPS & 47 PFLOPS \\
960$\times$960 & 921,600 & 82 PFLOPS & $\sim$148 PFLOPS & 738 PFLOPS \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Note:} ``Base Mode'' is raw optical performance without tower scaling. ``3\textsuperscript{3} MatMul'' applies the 1.8$\times$ boost (realistic for AI workloads). ``3\textsuperscript{3} Pure ADD'' applies the full 9$\times$ boost (only achievable for accumulation-dominated workloads).

\subsection{Comparison to State-of-the-Art}

\begin{table}[H]
\centering
\caption{Performance Comparison (Matrix Multiply Workloads)}
\begin{tabular}{@{}lrrr@{}}
\toprule
\textbf{System} & \textbf{Performance} & \textbf{Power} & \textbf{Nodes/Chips} \\
\midrule
NVIDIA B200 & 2.5 PFLOPS & 1,000W & 1 GPU \\
Optical 243$\times$243 & 9.4 PFLOPS & $\sim$100W & 1 chip \\
Optical 960$\times$960 & 148 PFLOPS & $\sim$400W & 1 chip \\
Frontier (Oak Ridge) & 1,200 PFLOPS & 21 MW & 9,402 nodes \\
Optical 960$\times$960 $\times$ 8 & $\sim$1,184 PFLOPS & $\sim$3.2 kW & 8 chips \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Critical distinction:} The above comparison uses the realistic 1.8$\times$ matrix multiply numbers. For pure ADD workloads (e.g., accumulation, vector operations), the picture changes dramatically:

\begin{table}[H]
\centering
\caption{Performance Comparison (Pure ADD Workloads)}
\begin{tabular}{@{}lrr@{}}
\toprule
\textbf{System} & \textbf{Performance} & \textbf{Chips to Match Frontier} \\
\midrule
Optical 960$\times$960 (Pure ADD) & 738 PFLOPS & 2 chips \\
\bottomrule
\end{tabular}
\end{table}

The ``2 chips = Frontier'' claim is accurate \textbf{only for pure ADD workloads}. For matrix multiplication (realistic AI training/inference), it is \textbf{8 chips = Frontier}. Both are remarkable—8 chips vs. 9,402 nodes is a 1,175$\times$ reduction in system complexity.

\section{N-Radix Input/Output Converter (NR-IOC)}

\subsection{Function}

The NR-IOC bridges binary electronic systems (PCIe, host CPU) with the optical ternary chip:

\begin{enumerate}
\item \textbf{Encode}: Binary $\rightarrow$ balanced ternary $\rightarrow$ optical wavelengths
\item \textbf{Apply 3\textsuperscript{3} interpretation}: Based on target PE type
\item \textbf{Decode}: Optical wavelengths $\rightarrow$ balanced ternary $\rightarrow$ binary
\end{enumerate}

\subsection{Timing}

NR-IOC conversion time is approximately \textbf{6.5 ns}—negligible compared to PCIe transfer latency ($\sim$1 $\mu$s per KB) and compute time.

\subsection{64-Bit Hardware as the Scaling Limit}

The optical hardware is unlimited—it simply adds wavelengths regardless of what they represent. The practical ceiling for tower scaling is determined by traditional 64-bit hardware at the host interface. The NR-IOC itself could handle higher tower levels, but the backend architecture cannot.

Testing reveals that 3\textsuperscript{3} encoding works with standard 64-bit hardware. Higher levels require arbitrary precision arithmetic, adding latency and complexity that negates the throughput benefit.

\section{The Vision: Frontier-Class Performance}

\subsection{Realistic Near-Term: Matrix Multiply Workloads}

For AI training and inference (matrix multiply workloads), the 1.8$\times$ tower scaling boost applies:

\begin{table}[H]
\centering
\caption{Matching Frontier for Matrix Multiply}
\begin{tabular}{@{}lrr@{}}
\toprule
\textbf{Configuration} & \textbf{Performance} & \textbf{vs Frontier} \\
\midrule
Single 960$\times$960 chip & 148 PFLOPS & 12.3\% \\
8 chips & 1,184 PFLOPS & $\sim$99\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{8 chips matching 9,402 Frontier nodes} represents a 1,175$\times$ reduction in system complexity at less than 0.02\% of the power requirement. This is the realistic comparison for AI workloads.

\subsection{Best-Case: Pure ADD Workloads}

For workloads dominated by accumulation (vector addition, certain scientific computing patterns), the full 9$\times$ tower scaling applies:

\begin{table}[H]
\centering
\caption{Matching Frontier for Pure ADD}
\begin{tabular}{@{}lrr@{}}
\toprule
\textbf{Configuration} & \textbf{Performance} & \textbf{vs Frontier} \\
\midrule
Single 960$\times$960 chip & 738 PFLOPS & 61.5\% \\
2 chips & 1,476 PFLOPS & $\sim$123\% \\
\bottomrule
\end{tabular}
\end{table}

The ``2 chips = Frontier'' claim is valid \textbf{only for pure ADD workloads}. This should be stated explicitly whenever cited.

\subsection{The Fundamental Shift}

Both scenarios represent a paradigm shift from ``more transistors = more compute'' to ``optical parallelism + tower scaling = more compute.'' The key insight is that even the ``conservative'' matrix multiply numbers (8 chips) represent extraordinary density compared to conventional supercomputers.

\section{Simulation Validation}

The architecture has been validated through FDTD electromagnetic simulations using Meep \cite{oskooi2010meep}. All simulation code is available in the open-source repository \cite{riner2026software}.

\subsection{Clock Distribution}

The central Kerr optical clock must reach all PEs within acceptable timing skew. We validated this for a 27$\times$27 array (729 PEs):

\begin{table}[H]
\centering
\caption{Clock Distribution Validation (27$\times$27 Array)}
\begin{tabular}{@{}lr@{}}
\toprule
\textbf{Metric} & \textbf{Result} \\
\midrule
Array size & 27$\times$27 (729 PEs) \\
Wavelength & 1550 nm (C-band) \\
Measured clock skew & 39.3 femtoseconds \\
Skew as \% of period & 2.4\% \\
Threshold & 5\% \\
\textbf{Status} & \textbf{PASS} \\
\bottomrule
\end{tabular}
\end{table}

The 39 fs skew corresponds to approximately 12 $\mu$m of optical path difference---well within fabrication tolerances for silicon photonics.

\subsection{WDM Channel Isolation}

The wavelength-division multiplexing scheme was validated across multiple array sizes to ensure spectral isolation between the three wavelength channels:

\begin{table}[H]
\centering
\caption{WDM Validation Results}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Array Size} & \textbf{PEs} & \textbf{Crosstalk} & \textbf{Status} \\
\midrule
3$\times$3 & 9 & $<$-30 dB & PASS \\
9$\times$9 & 81 & $<$-30 dB & PASS \\
27$\times$27 & 729 & $<$-30 dB & PASS \\
81$\times$81 & 6,561 & 81/81 ports & PASS \\
\bottomrule
\end{tabular}
\end{table}

The collision-free wavelength triplet (1550/1310/1064 nm) maintains $>$10 nm spacing between all SFG mixer outputs, ensuring reliable wavelength discrimination at scale.

\subsection{Scaling Projections}

Based on validated 27$\times$27 results, analytical projections support scaling to larger arrays:

\begin{itemize}
\item \textbf{81$\times$81}: \textbf{VALIDATED} - All 81 output ports detected all 18 wavelengths (6,561 PEs confirmed working)
\item \textbf{243$\times$243}: Projected viable with H-tree clock distribution
\item \textbf{960$\times$960}: Theoretical target; may require clock domain partitioning
\end{itemize}

The key insight from validation: \textbf{the physics scales}. Optical path lengths are predictable, wavelength isolation is maintained, and timing skew grows sub-linearly with array size due to the central clock architecture.

\section{Cybersecurity Benefits}

N-Radix offers an unconventional security advantage: \textbf{the geometry is the program}.

Traditional processors execute software—instructions stored in memory, interpreted by logic circuits. This creates an attack surface: buffer overflows, firmware exploits, side-channel attacks, malicious code injection. Every layer of software is a potential vulnerability.

The optical compute core has no software. It is glass and waveguides. Computation is determined by the physical layout—where waveguides meet, how ring resonators are positioned, how light paths intersect. There is no instruction set to exploit, no firmware to corrupt, no memory to overflow.

\textbf{To ``hack'' the optical core, you would need to physically alter the glass.}

The optical compute core is immune to:
\begin{itemize}
\item \textbf{Remote code execution}: No code to execute in glass
\item \textbf{Firmware attacks}: No firmware in the optical path
\item \textbf{Persistent malware}: Cannot install software in waveguides
\item \textbf{Logic manipulation}: Computation is fixed by geometry
\end{itemize}

\subsection{Important Limitations}

We must be clear about what this does \emph{not} protect:

\begin{itemize}
\item \textbf{System interfaces}: The NR-IOC, PCIe bus, and host system are electronic and require traditional security practices
\item \textbf{Input/output manipulation}: An attacker who compromises the host could manipulate data before it reaches the optical core or after it returns
\item \textbf{Manufacturing trust}: The foundry that fabricates the chip knows the geometry—supply chain security remains a consideration
\end{itemize}

The security model is analogous to a vault: the optical core (vault) cannot be breached remotely, but the building around it (interfaces, host system) still requires protection. Even if an attacker compromises the electronic interfaces, they cannot alter what the optical core computes—the geometry is physically fixed.

\subsection{The Core Advantage}

For high-assurance applications—cryptographic key storage, secure enclaves, critical infrastructure—the value is clear: \textbf{the compute logic itself has no software attack surface}. Traditional security protects the perimeter; optical geometry protects the core. Defense in depth with a physically immutable foundation.

\section{Conclusion}

We have presented the N-Radix architecture, extending wavelength-division ternary logic into a practical AI accelerator design. Key contributions include:

\begin{enumerate}
\item \textbf{Systolic array architecture}: Based on Kung and Leiserson's foundational systolic design, implemented with optical ternary PEs
\item \textbf{Log-domain tower scaling}: 3\textsuperscript{3} encoding yields 9$\times$ throughput for pure ADD operations, $\sim$1.8$\times$ for matrix multiply (via Amdahl's Law on the 50/50 ADD/MUL split)
\item \textbf{Practical limits identified}: 3\textsuperscript{3}\textsuperscript{3}\textsuperscript{3} requires 12 terabit registers—beyond physical realizability
\item \textbf{64-bit hardware as the true ceiling}: The optical hardware is unlimited; 64-bit hardware can handle 3\textsuperscript{3} encoding but not higher towers
\item \textbf{Honest performance claims}: 8 chips match Frontier for matrix multiply; 2 chips match Frontier only for pure ADD workloads
\item \textbf{FDTD validation}: Clock distribution and WDM isolation validated through electromagnetic simulation up to 27$\times$27 arrays
\item \textbf{Architectural security}: The optical core has no software attack surface; system interfaces require traditional protection
\end{enumerate}

The architecture offers a path to supercomputer-class performance in dramatically smaller form factors. At 960$\times$960 scale with 3\textsuperscript{3} encoding:
\begin{itemize}
\item \textbf{Base mode}: 82 PFLOPS/chip
\item \textbf{Matrix multiply (1.8$\times$)}: $\sim$148 PFLOPS/chip
\item \textbf{Pure ADD (9$\times$)}: 738 PFLOPS/chip
\end{itemize}

Even the conservative matrix multiply numbers represent a transformative improvement: 8 chips at less than 0.02\% the power vs.\ Frontier's 9,402 nodes. The fundamental physics allows it; the engineering challenge is now clearly defined.

\subsection*{Ongoing Work}

The weight streaming architecture described in this paper relies on a 3-tier optical RAM hierarchy. While the architecture is defined, validation of weight storage mechanisms and streaming integration with the systolic array is currently in progress. Results will be presented in subsequent work.

\section*{Acknowledgment}

Claude (Anthropic) provided assistance by building the tools to test the author's architectural decisions—FDTD simulations, architecture code, and driver implementations. The core innovations—wavelength-division ternary encoding, log-domain tower scaling, N-Radix architecture, and the insight that optical geometry eliminates software attack surfaces—are the work of the author.

\begin{thebibliography}{10}

\bibitem{riner2026wavelength}
C. Riner, ``Wavelength-Division Ternary Logic: Bypassing the Radix Economy Penalty in Optical Computing,'' Zenodo, Jan. 2026. DOI: 10.5281/zenodo.18437600

\bibitem{riner2026software}
C. Riner, ``Wavelength-Division Ternary Optical Computer,'' Zenodo, Feb. 2026. Software. DOI: 10.5281/zenodo.14797981

\bibitem{knuth1981}
D. E. Knuth, \emph{The Art of Computer Programming, Volume 2: Seminumerical Algorithms}, 2nd ed. Addison-Wesley, 1981.

\bibitem{hayes2001}
B. Hayes, ``Third base,'' \emph{American Scientist}, vol. 89, no. 6, pp. 490--494, 2001.

\bibitem{hurst1984}
S. L. Hurst, ``Multiple-valued logic---its status and its future,'' \emph{IEEE Trans. Computers}, vol. C-33, no. 12, pp. 1160--1179, 1984.

\bibitem{jouppi2017}
N. P. Jouppi et al., ``In-datacenter performance analysis of a tensor processing unit,'' \emph{Proc. 44th Annual Int. Symp. Computer Architecture}, pp. 1--12, 2017.

\bibitem{miller2010}
D. A. B. Miller, ``Are optical transistors the logical next step?'' \emph{Nature Photonics}, vol. 4, no. 1, pp. 3--5, 2010.

\bibitem{caulfield2010}
H. J. Caulfield and S. Dolev, ``Why future supercomputing requires optics,'' \emph{Nature Photonics}, vol. 4, no. 5, pp. 261--263, 2010.

\bibitem{kung1982}
H. T. Kung and C. E. Leiserson, ``Systolic arrays (for VLSI),'' \emph{Sparse Matrix Proceedings 1978}, SIAM, pp. 256--282, 1979.

\bibitem{oskooi2010meep}
A. F. Oskooi et al., ``Meep: A flexible free-software package for electromagnetic simulations by the FDTD method,'' \emph{Computer Physics Communications}, vol. 181, no. 3, pp. 687--702, 2010.

\end{thebibliography}

\end{document}
