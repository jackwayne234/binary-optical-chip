\documentclass[journal]{IEEEtran}

% Packages
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{cite}
\usepackage{url}
\usepackage{hyperref}
\usepackage{float}
\usepackage{booktabs}
\usepackage{multirow}

% Correct hyphenation
\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}

\title{N-Radix: A Wavelength-Division Optical Accelerator\\Bypassing the Radix Economy Penalty}

\author{Christopher Riner%
\thanks{Independent Researcher: Chesapeake, VA, US. Email: chrisriner45@gmail.com}}

\maketitle

\begin{abstract}
We present N-Radix, an optical accelerator architecture based on wavelength-division ternary logic. Building on our prior theoretical work demonstrating that wavelength encoding bypasses the radix economy penalty, we now describe a complete systolic array architecture optimized for AI/ML workloads. The design employs a novel log-domain tower scaling mechanism where the Input/Output Converter (IOC) reinterprets base-3 trits as $\text{trit}^3$ (3\textsuperscript{3} encoding), yielding up to 9$\times$ throughput improvement for pure addition workloads while using identical optical hardware. We analyze the practical limits of this scaling approach, showing that while 3\textsuperscript{3} encoding is achievable with standard 64-bit hardware, higher towers (3\textsuperscript{3}\textsuperscript{3}\textsuperscript{3}) would require 12 terabit registers—placing them beyond physical realizability. For real-world matrix multiplication workloads (50\% multiply, 50\% add), the architecture delivers approximately 1.8$\times$ throughput improvement via Amdahl's Law. At 960$\times$960 scale, this yields 148 PFLOPS per chip for matrix multiply—meaning 8 chips could match Frontier's 1,200 PFLOPS, compared to Frontier's 9,402 nodes.
\end{abstract}

\begin{IEEEkeywords}
Ternary computing, optical computing, N-Radix, systolic array, wavelength division, radix economy, log-domain computing, AI accelerator
\end{IEEEkeywords}

\section{Introduction}

In our prior work \cite{riner2026wavelength}, we demonstrated that wavelength-division ternary logic fundamentally bypasses the radix economy penalty that has historically prevented ternary computing from practical realization. While transistor-based ternary requires approximately 40$\times$ more hardware per trit compared to binary bits, wavelength differentiation cost is independent of the number of states.

This paper extends that theoretical foundation into a complete accelerator architecture we call \textbf{N-Radix}---named for its ability to operate at any radix without penalty. The design is optimized for AI and machine learning workloads. We introduce:

\begin{enumerate}
\item A \textbf{systolic array architecture} where processing elements (PEs) perform optical add/subtract operations on wavelength-encoded trits
\item \textbf{Log-domain tower scaling} that increases effective throughput by reinterpreting trit values at the system boundary
\item \textbf{Input/Output Converter (IOC)} specifications for bridging binary electronic systems with optical ternary computation
\item \textbf{Practical performance analysis} showing realistic throughput gains for matrix multiply workloads
\end{enumerate}

\section{Wavelength Encoding Review}

\subsection{Balanced Ternary States}

Each ternary digit (trit) is encoded as one of three discrete wavelengths:

\begin{table}[H]
\centering
\caption{Wavelength-Trit Mapping (Collision-Free)}
\begin{tabular}{@{}ccc@{}}
\toprule
\textbf{Trit Value} & \textbf{Wavelength} & \textbf{Band} \\
\midrule
$-1$ & 1550 nm & C-Band Telecom \\
$0$ & 1310 nm & O-Band Telecom \\
$+1$ & 1064 nm & Nd:YAG Standard \\
\bottomrule
\end{tabular}
\label{tab:wavelengths}
\end{table}

This triplet was selected to ensure all six Sum-Frequency Generation (SFG) mixer outputs are spectrally unique with $>$10 nm spacing, avoiding the output collision present in earlier wavelength selections.

\subsection{Why Wavelength Encoding Bypasses Radix Economy}

In transistor-based systems, distinguishing $r$ voltage states requires circuitry proportional to $r$, resulting in a hardware penalty that negates ternary's theoretical 58\% information density advantage. In wavelength-encoded systems, a wavelength-selective switch (ring resonator) has approximately constant complexity regardless of how many wavelengths it distinguishes. The cost model becomes:

\begin{equation}
\text{Cost}_{\text{wavelength}} \approx C_{\text{switch}} + C_{\text{demux}}/\text{fanout}
\end{equation}

where $C_{\text{switch}}$ is approximately \textbf{constant} regardless of radix.

\section{N-Radix Architecture}

\subsection{Systolic Array Design}

N-Radix employs a systolic array architecture identical in topology to Google's TPU and NVIDIA's tensor cores. Data flows through a 2D grid of Processing Elements (PEs), with each PE performing multiply-accumulate operations as data passes through.

\begin{figure}[H]
\centering
\begin{verbatim}
    Weight inputs (stationary in PEs)
                ↓
    ┌─────────────────────────────────┐
    │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
A → │   PE─PE─PE─PE─PE─PE─PE─PE─PE → C
c   │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
t   │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
i   │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
v   │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
a   │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
t   │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
i   │   PE─PE─PE─PE─PE─PE─PE─PE─PE   │
o   │             ↓                   │
n   │      Accumulated outputs        │
s   └─────────────────────────────────┘
\end{verbatim}
\caption{Systolic array topology. Activations stream from left, weights are stationary in PEs, accumulated outputs flow down.}
\label{fig:systolic}
\end{figure}

\subsection{Processing Element Design}

Each PE contains:

\begin{enumerate}
\item \textbf{Weight register}: Bistable Kerr resonator storing one 9-trit weight
\item \textbf{SFG mixer}: Performs optical multiply (in log domain) or add (in linear domain)
\item \textbf{Accumulator}: Aggregates partial sums
\end{enumerate}

\subsubsection{Weight Storage via Bistable Kerr Resonators}

Weights are stored using the optical Kerr effect ($\chi^{(3)}$ nonlinearity), which creates bistable states. Each trit locks to one of three wavelengths:

\begin{itemize}
\item High-power 1550 nm pulse $\rightarrow$ locks to $-1$
\item High-power 1310 nm pulse $\rightarrow$ locks to $0$
\item High-power 1064 nm pulse $\rightarrow$ locks to $+1$
\end{itemize}

Write time is approximately 10 ns per trit. No refresh is required (unlike DRAM)—weights persist until explicitly overwritten.

\subsection{PE Types and Operations}

The architecture employs two types of PEs:

\begin{table}[H]
\centering
\caption{Processing Element Types}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{PE Type} & \textbf{Domain} & \textbf{Physical Operation} \\
\midrule
ADD/SUB & Linear & Optical add/subtract \\
MUL/DIV & Log & Optical add/subtract (= mul/div) \\
\bottomrule
\end{tabular}
\end{table}

Both PE types perform identical physical operations (optical add/subtract). The difference is purely in interpretation: MUL/DIV PEs operate on log-encoded values, so optical addition corresponds to multiplication in the original linear domain.

\section{Log-Domain Tower Scaling}

\subsection{The Core Insight}

In the log domain:
\begin{align}
\log(A \times B) &= \log(A) + \log(B) \\
\log(A / B) &= \log(A) - \log(B)
\end{align}

Multiplication and division become addition and subtraction—enabling all arithmetic using only add/subtract hardware.

Taking this further, in the \textbf{log-log domain}:
\begin{equation}
\log(\log(X^n)) = \log(n \cdot \log(X)) = \log(n) + \log(\log(X))
\end{equation}

Exponentiation becomes addition. Each additional log level converts a harder operation into simple add/subtract.

\subsection{3\textsuperscript{3} Encoding}

Rather than adding hardware complexity, we increase effective throughput by having the IOC \textbf{reinterpret} what each trit represents:

\begin{table}[H]
\centering
\caption{Tower Scaling Levels}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Level} & \textbf{Domain} & \textbf{Trit Represents} & \textbf{Hardware} \\
\midrule
0 & Linear & trit & Add/sub \\
1 & Log & trit & Add/sub = mul/div \\
2 & Log-log & trit$^3$ & Add/sub \\
\bottomrule
\end{tabular}
\end{table}

The optical hardware remains identical—3 physical states, 3 wavelengths. The IOC handles encoding/decoding at the boundary.

\subsection{Practical Implementation}

Both ADD/SUB and MUL/DIV PEs use \textbf{3\textsuperscript{3} encoding}:

\begin{itemize}
\item ADD/SUB PEs: trit$^3$ represents addition values
\item MUL/DIV PEs: trit$^3$ represents multiplication values (in log domain)
\end{itemize}

The IOC knows which PE type it addresses and applies the correct interpretation.

\subsection{Why 3\textsuperscript{3}\textsuperscript{3}\textsuperscript{3} Is Beyond Engineering}

Theoretically, MUL/DIV operations could achieve pure add/subtract at tower level 4 (3\textsuperscript{3}\textsuperscript{3}\textsuperscript{3}). However, this would require:

\begin{equation}
3^{3^{3^3}} = 3^{3^{27}} = 3^{7,625,597,484,987}
\end{equation}

This number has approximately \textbf{3.6 trillion decimal digits} and would require:

\begin{itemize}
\item \textbf{12 terabit registers} (12 trillion bits)
\item \textbf{1.5 terabytes} to store a single number
\end{itemize}

\begin{table}[H]
\centering
\caption{Bit Width Comparison}
\begin{tabular}{@{}lrl@{}}
\toprule
\textbf{System} & \textbf{Bits} & \textbf{Max Value} \\
\midrule
Standard & 64 & $\sim 10^{19}$ \\
Extended & 128 & $\sim 10^{38}$ \\
Cryptographic & 256 & $\sim 10^{77}$ \\
Large & 512 & $\sim 10^{154}$ \\
\textbf{3\textsuperscript{3}\textsuperscript{3}\textsuperscript{3}} & \textbf{12 trillion} & $\sim 10^{3.6 \text{ trillion}}$ \\
\bottomrule
\end{tabular}
\end{table}

This is not future hardware—it is mathematically beyond any physical computer. Therefore, \textbf{3\textsuperscript{3} encoding is the practical ceiling}.

\section{Performance Analysis}

\subsection{Throughput with 3\textsuperscript{3} Encoding}

The 3\textsuperscript{3} encoding provides a 9$\times$ effective throughput increase for operations that benefit from it. However, \textbf{only ADD/SUB operations benefit}—MUL/DIV operations remain at baseline throughput. This distinction is critical for understanding real-world performance.

\subsection{Real-World Matrix Multiply Performance}

Matrix multiplication consists of approximately:
\begin{itemize}
\item 50\% multiply operations
\item 50\% add operations (accumulation)
\end{itemize}

Applying Amdahl's Law:

\begin{equation}
\text{Speedup} = \frac{1}{\frac{0.5}{9} + \frac{0.5}{1}} = \frac{1}{0.056 + 0.5} \approx 1.8\times
\end{equation}

\begin{table}[H]
\centering
\caption{Performance by Workload Type}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Workload} & \textbf{ADD \%} & \textbf{MUL \%} & \textbf{Boost} \\
\midrule
Matrix multiply & 50\% & 50\% & $\sim$1.8$\times$ \\
Transformer attention & 60\% & 40\% & $\sim$2.1$\times$ \\
Pure accumulation & 100\% & 0\% & 9$\times$ \\
Pure multiply & 0\% & 100\% & 1$\times$ \\
\bottomrule
\end{tabular}
\label{tab:performance}
\end{table}

\textbf{Key insight:} The 9$\times$ boost only applies to ADD-heavy workloads (e.g., pure accumulation, vector addition). For realistic AI workloads like matrix multiplication, the 50/50 split between ADD and MUL operations limits the effective boost to $\sim$1.8$\times$ via Amdahl's Law. This is still substantial—but claims must be workload-specific.

\subsection{Scaling Projections}

\begin{table}[H]
\centering
\caption{Array Size vs Performance (Three Modes)}
\begin{tabular}{@{}lrrrr@{}}
\toprule
\textbf{Array} & \textbf{PEs} & \textbf{Base Mode} & \textbf{3\textsuperscript{3} MatMul} & \textbf{3\textsuperscript{3} Pure ADD} \\
\midrule
27$\times$27 & 729 & 65 TFLOPS & 117 TFLOPS & 583 TFLOPS \\
81$\times$81 & 6,561 & 583 TFLOPS & 1.0 PFLOPS & 5.2 PFLOPS \\
243$\times$243 & 59,049 & 5.2 PFLOPS & 9.4 PFLOPS & 47 PFLOPS \\
960$\times$960 & 921,600 & 82 PFLOPS & $\sim$148 PFLOPS & 738 PFLOPS \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Note:} ``Base Mode'' is raw optical performance without tower scaling. ``3\textsuperscript{3} MatMul'' applies the 1.8$\times$ boost (realistic for AI workloads). ``3\textsuperscript{3} Pure ADD'' applies the full 9$\times$ boost (only achievable for accumulation-dominated workloads).

\subsection{Comparison to State-of-the-Art}

\begin{table}[H]
\centering
\caption{Performance Comparison (Matrix Multiply Workloads)}
\begin{tabular}{@{}lrrr@{}}
\toprule
\textbf{System} & \textbf{Performance} & \textbf{Power} & \textbf{Nodes/Chips} \\
\midrule
NVIDIA B200 & 2.5 PFLOPS & 1,000W & 1 GPU \\
Optical 243$\times$243 & 9.4 PFLOPS & $\sim$100W & 1 chip \\
Optical 960$\times$960 & 148 PFLOPS & $\sim$400W & 1 chip \\
Frontier (Oak Ridge) & 1,200 PFLOPS & 21 MW & 9,402 nodes \\
Optical 960$\times$960 $\times$ 8 & $\sim$1,184 PFLOPS & $\sim$3.2 kW & 8 chips \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Critical distinction:} The above comparison uses the realistic 1.8$\times$ matrix multiply numbers. For pure ADD workloads (e.g., accumulation, vector operations), the picture changes dramatically:

\begin{table}[H]
\centering
\caption{Performance Comparison (Pure ADD Workloads)}
\begin{tabular}{@{}lrr@{}}
\toprule
\textbf{System} & \textbf{Performance} & \textbf{Chips to Match Frontier} \\
\midrule
Optical 960$\times$960 (Pure ADD) & 738 PFLOPS & 2 chips \\
\bottomrule
\end{tabular}
\end{table}

The ``2 chips = Frontier'' claim is accurate \textbf{only for pure ADD workloads}. For matrix multiplication (realistic AI training/inference), it is \textbf{8 chips = Frontier}. Both are remarkable—8 chips vs. 9,402 nodes is a 1,175$\times$ reduction in system complexity.

\section{Input/Output Converter (IOC)}

\subsection{Function}

The IOC bridges binary electronic systems (PCIe, host CPU) with the optical ternary chip:

\begin{enumerate}
\item \textbf{Encode}: Binary $\rightarrow$ balanced ternary $\rightarrow$ optical wavelengths
\item \textbf{Apply 3\textsuperscript{3} interpretation}: Based on target PE type
\item \textbf{Decode}: Optical wavelengths $\rightarrow$ balanced ternary $\rightarrow$ binary
\end{enumerate}

\subsection{Timing}

IOC conversion time is approximately \textbf{6.5 ns}—negligible compared to PCIe transfer latency ($\sim$1 $\mu$s per KB) and compute time.

\subsection{The IOC as the Scaling Limit}

The optical hardware is unlimited—it simply adds wavelengths regardless of what they represent. The practical ceiling for tower scaling is determined by:

\begin{enumerate}
\item \textbf{IOC precision}: How many tower levels can be accurately encoded/decoded
\item \textbf{Transistor interface}: PCIe bandwidth and host CPU capabilities
\end{enumerate}

Testing reveals that 3\textsuperscript{3} encoding works with standard 64-bit hardware. Higher levels require arbitrary precision arithmetic, adding latency and complexity that negates the throughput benefit.

\section{The Vision: Frontier-Class Performance}

\subsection{Realistic Near-Term: Matrix Multiply Workloads}

For AI training and inference (matrix multiply workloads), the 1.8$\times$ tower scaling boost applies:

\begin{table}[H]
\centering
\caption{Matching Frontier for Matrix Multiply}
\begin{tabular}{@{}lrr@{}}
\toprule
\textbf{Configuration} & \textbf{Performance} & \textbf{vs Frontier} \\
\midrule
Single 960$\times$960 chip & 148 PFLOPS & 12.3\% \\
8 chips & 1,184 PFLOPS & $\sim$99\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{8 chips matching 9,402 Frontier nodes} represents a 1,175$\times$ reduction in system complexity. This is the realistic comparison for AI workloads.

\subsection{Best-Case: Pure ADD Workloads}

For workloads dominated by accumulation (vector addition, certain scientific computing patterns), the full 9$\times$ tower scaling applies:

\begin{table}[H]
\centering
\caption{Matching Frontier for Pure ADD}
\begin{tabular}{@{}lrr@{}}
\toprule
\textbf{Configuration} & \textbf{Performance} & \textbf{vs Frontier} \\
\midrule
Single 960$\times$960 chip & 738 PFLOPS & 61.5\% \\
2 chips & 1,476 PFLOPS & $\sim$123\% \\
\bottomrule
\end{tabular}
\end{table}

The ``2 chips = Frontier'' claim is valid \textbf{only for pure ADD workloads}. This should be stated explicitly whenever cited.

\subsection{The Fundamental Shift}

Both scenarios represent a paradigm shift from ``more transistors = more compute'' to ``optical parallelism + tower scaling = more compute.'' The key insight is that even the ``conservative'' matrix multiply numbers (8 chips) represent extraordinary density compared to conventional supercomputers.

\section{Conclusion}

We have presented the N-Radix architecture, extending wavelength-division ternary logic into a practical AI accelerator design. Key contributions include:

\begin{enumerate}
\item \textbf{Systolic array architecture}: Identical topology to proven designs (Google TPU, NVIDIA tensor cores), but with optical ternary PEs
\item \textbf{Log-domain tower scaling}: 3\textsuperscript{3} encoding yields 9$\times$ throughput for pure ADD operations, $\sim$1.8$\times$ for matrix multiply (via Amdahl's Law on the 50/50 ADD/MUL split)
\item \textbf{Practical limits identified}: 3\textsuperscript{3}\textsuperscript{3}\textsuperscript{3} requires 12 terabit registers—beyond physical realizability
\item \textbf{IOC as the true ceiling}: The optical hardware is unlimited; scaling is bounded by electronic interface precision
\item \textbf{Honest performance claims}: 8 chips match Frontier for matrix multiply; 2 chips match Frontier only for pure ADD workloads
\end{enumerate}

The architecture offers a path to supercomputer-class performance in dramatically smaller form factors. At 960$\times$960 scale with 3\textsuperscript{3} encoding:
\begin{itemize}
\item \textbf{Base mode}: 82 PFLOPS/chip
\item \textbf{Matrix multiply (1.8$\times$)}: $\sim$148 PFLOPS/chip
\item \textbf{Pure ADD (9$\times$)}: 738 PFLOPS/chip
\end{itemize}

Even the conservative matrix multiply numbers represent a transformative improvement: 8 chips vs.\ Frontier's 9,402 nodes. The fundamental physics allows it; the engineering challenge is now clearly defined.

\section*{Acknowledgment}

Claude (Anthropic) provided assistance with architectural documentation and performance analysis. The core innovations—wavelength-division ternary encoding, log-domain tower scaling, and N-Radix architecture—are the work of the author.

\begin{thebibliography}{10}

\bibitem{riner2026wavelength}
C. Riner, ``Wavelength-Division Ternary Logic: Bypassing the Radix Economy Penalty in Optical Computing,'' Zenodo, Jan. 2026. DOI: 10.5281/zenodo.18437600

\bibitem{knuth1981}
D. E. Knuth, \emph{The Art of Computer Programming, Volume 2: Seminumerical Algorithms}, 2nd ed. Addison-Wesley, 1981.

\bibitem{hayes2001}
B. Hayes, ``Third base,'' \emph{American Scientist}, vol. 89, no. 6, pp. 490--494, 2001.

\bibitem{hurst1984}
S. L. Hurst, ``Multiple-valued logic---its status and its future,'' \emph{IEEE Trans. Computers}, vol. C-33, no. 12, pp. 1160--1179, 1984.

\bibitem{jouppi2017}
N. P. Jouppi et al., ``In-datacenter performance analysis of a tensor processing unit,'' \emph{Proc. 44th Annual Int. Symp. Computer Architecture}, pp. 1--12, 2017.

\bibitem{miller2010}
D. A. B. Miller, ``Are optical transistors the logical next step?'' \emph{Nature Photonics}, vol. 4, no. 1, pp. 3--5, 2010.

\bibitem{caulfield2010}
H. J. Caulfield and S. Dolev, ``Why future supercomputing requires optics,'' \emph{Nature Photonics}, vol. 4, no. 5, pp. 261--263, 2010.

\bibitem{oskooi2010meep}
A. F. Oskooi et al., ``Meep: A flexible free-software package for electromagnetic simulations by the FDTD method,'' \emph{Computer Physics Communications}, vol. 181, no. 3, pp. 687--702, 2010.

\end{thebibliography}

\end{document}
